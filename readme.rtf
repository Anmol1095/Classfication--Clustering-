{\rtf1\ansi\ansicpg1252\cocoartf2513
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica-Bold;\f1\froman\fcharset0 Times-Roman;\f2\froman\fcharset0 Times-Bold;
}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\b\fs34\fsmilli17333 \cf2 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 1 Classification \
\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf2 (i) number of instances, (ii) number of missing values, (iii) fraction of missing values over all attribute values, (iv) number of instances with missing values and (v) fraction of instances with missing values over all instances.\
\
\pard\pardeftab720\partightenfactor0
\cf2 Convert all 13 attributes into nominal using a Scikit-learn LabelEncoder.\
\
the error rate of the resulting tree\
\
Train two decision trees with these two data sets and compare their error rates using instances from D for testing. Briefly comment on the obtained results.\
\
\pard\pardeftab720\partightenfactor0

\f0\b\fs36 \cf2 \outl0\strokewidth0 2 
\f2 \outl0\strokewidth0 Clustering
\f0 \outl0\strokewidth0  \
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf2 \outl0\strokewidth0 a table in the report with the mean minimum and maximum attribute \
Run k-means with k = 3 and constructed a scatterplot for each pair of attributes using Pyplot}